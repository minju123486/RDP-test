import numpy as np
X = [0,1] # source
px = [1/2, 1/2] # source
X_hat = [0,1]
pX_hat = [1/2, 1/2]
X_HatcoditionedX = [[0,1],[0,1]]
pX_HatcoditionedX = [[0.67, 0.33], [0.33, 0.67]]
pXY = [[0.335, 0.165],[0.165, 0.335]]


def Hamming_distortion(X, Xhat):
    assert X.shape == Xhat.shape, "X와 Xhat shape이 다름"
    mism = (X != Xhat)
    cnt = np.count_nonzero(mism)
    return cnt


import numpy as np

def random_bit(size=None):
    return np.random.randint(0, 2, size=size)

print(random_bit())          # 단일 0 또는 1
print(random_bit(10))        # [0 1 0 1 1 0 0 1 0 1]



import math
def mutual_information(X,Xhat):
    hap = 0
    for x in X:
        for x_hat in X_hat:
            hap += (px[x] * pX_HatcoditionedX[x_hat][x] * 
                    math.log2(px[x] * pX_HatcoditionedX[x_hat][x]/(px[x]*
                                                                pX_hat[x_hat]))
                   )
    return hap        


mutual_information(X, X_hat)


import numpy as np

#조건부 분포 검증

# 정의
X_vals = np.array([0, 1])
pX = np.array([0.5, 0.5])
pX_hat = np.array([0.5, 0.5])
pXhat_given_X = np.array([[0.67, 0.33],
                          [0.33, 0.67]]) 

# 샘플 수
N = 100_000

# 1. X 샘플링 (Bern(1/2))
X_samples = np.random.choice(X_vals, size=N, p=pX)

# 2. X_hat 샘플링 (조건부 분포 이용)
Xhat_samples = np.empty(N, dtype=int)
for i, x in enumerate(X_samples):
    Xhat_samples[i] = np.random.choice(X_vals, p=pXhat_given_X[x])

# 3. joint 빈도 및 왜곡 확인
joint_counts = np.zeros((2, 2))
for x, xhat in zip(X_samples, Xhat_samples):
    joint_counts[x, xhat] += 1
joint_probs = joint_counts / N

# 4. 평균 왜곡 (해밍)
distortion = np.mean(X_samples != Xhat_samples)

print("Joint empirical p(x, x̂):")
print(joint_probs)
print(f"평균 왜곡 ≈ {distortion:.3f}")


Xhat_samples


def codebook_generation(n, R, distribution):
    M = int(2 ** (n*R))
    codebook = np.random.choice([0, 1], size=(M, n), p=distribution)
    return codebook


n=150
R=0.11
codebook = codebook_generation(n, R, pX_hat)
codebook.shape
np.sum(codebook, axis = 1).shape



count = 1
for i in range(count):
    xn = random_bit(n)
    


def joint_empirical_pmf(x_seq: np.ndarray, y_seq: np.ndarray, X_alphabet, Y_alphabet):
    x_seq = np.asarray(x_seq)                     # 예: array([0,1,1,0])
    y_seq = np.asarray(y_seq)                     # 예: array([0,1,1,0])
    assert x_seq.shape == y_seq.shape and x_seq.ndim == 1

    # map symbols to indices
    x_to_idx = {sym:i for i, sym in enumerate(X_alphabet)}   # {0:0, 1:1}
    y_to_idx = {sym:j for j, sym in enumerate(Y_alphabet)}   # {0:0, 1:1}
    kx, ky = len(X_alphabet), len(Y_alphabet)                # kx=2, ky=2

    # encode to indices
    xi = np.vectorize(x_to_idx.__getitem__)(x_seq)           # [0,1,1,0]
    yj = np.vectorize(y_to_idx.__getitem__)(y_seq)           # [0,1,1,0]
    # joint counts
    idx = xi * ky + yj                                       
    # ky=2 이므로 xi*2 + yj → [0*2+0, 1*2+1, 1*2+1, 0*2+0] = [0,3,3,0]

    counts = np.bincount(idx, minlength=kx*ky).astype(float).reshape(kx, ky)
    # idx=[0,3,3,0] 이므로 bincount: [2,0,0,2] → reshape(2x2)=[[2,0],[0,2]]
    return counts / x_seq.size 
    # x_seq.size = 4 → [[2/4, 0/4],[0/4, 2/4]]
    # 결과: array([[0.5, 0.0], [0.0, 0.5]])


def is_jointly_typical(x_seq,
                       y_seq,
                       pXY,
                       X_alphabet,
                       Y_alphabet,
                       eps: float):
    """
    (x^n, y^n)이 주어졌을 때,
    정의:
      |π(x,y) - pXY(x,y)| <= eps * pXY(x,y)  (pXY(x,y) > 0인 모든 (x,y))
    이고,
      pXY(x,y) = 0 인 자리에서는 π(x,y)도 0 이어야 함
    을 만족하면 True (joint ε-typical), 아니면 False.
    """
    # 경험적 joint pmf π(x,y)
    pi = joint_empirical_pmf(x_seq, y_seq, X_alphabet, Y_alphabet)

    # 이론 joint pmf
    pXY = np.asarray(pXY, dtype=float)
    assert pi.shape == pXY.shape, "π와 pXY의 shape이 다릅니다."

    # (1) pXY(x,y) > 0 인 위치: 상대 오차 조건 검사
    pos = pXY > 0
    if np.any(np.abs(pi[pos] - pXY[pos]) > eps * pXY[pos]):
        return False

    # (2) pXY(x,y) = 0 인 위치: 실제로도 안 나와야 함
    zero = ~pos
    if np.any(pi[zero] > 0):
        return False

    return True



N=100000
joint_empirical_pmf(np.random.choice(X_vals, size=N,p=px),np.random.choice(X_vals,  size=N,p=pX_hat),X,X_hat)


count = 1000
zero_cnt = 0
for i in range(count):
    xn = random_bit(n)  # source block X^n
    found_index = None
    for idx, tempt in enumerate(codebook):   # tempt = codeword candidate
        if is_jointly_typical(xn, tempt, pXY, X, X_hat, eps=0.15):
            found_index = idx
            break

    if found_index is None:
        found_index = 0  # 못 찾았을 때 기본값 (논문에서 m=1)
        zero_cnt += 1
    print(f"Block {i}: chosen codeword index = {found_index}")
print("Error source count = ", zero_cnt)


print("eps=0.11, Error source count =  483"



